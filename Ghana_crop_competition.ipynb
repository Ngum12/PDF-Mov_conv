{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW1jPgK75i4s2zVz4zW9uo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ngum12/PDF-Mov_conv/blob/main/Ghana_crop_competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wunjhNlD63-t",
        "outputId": "f131b752-3308-4dee-cea5-987749303184"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY6cm6nW7Eek",
        "outputId": "fd340fb6-7423-43ce-f507-6f52742f0251"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjLhvZp9jQ21",
        "outputId": "c9f28120-3da5-4944-d322-5aed99510494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.15-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.3.15-py3-none-any.whl (870 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m870.5/870.5 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.15 ultralytics-thop-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlfGCWq35fcZ",
        "outputId": "17a2114f-e52c-46b6-bcf7-70df47b168f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Current working directory: /content/drive/My Drive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i\n",
            "\n",
            "Files in base directory:\n",
            "dataset\t\t\t\t\t\t\t\t     runs\n",
            "data.yaml\t\t\t\t\t\t\t     SampleSubmission.csv\n",
            "ghana-crop-disease-detection-challenge20241003-7123-59ht2i\t     Test.csv\n",
            "images.zip\t\t\t\t\t\t\t     Train.csv\n",
            "manifest-8517f262e2ca61a7f7ac8fc1d32eb0be20241003-7123-1lvxb66.json  yolov8n.pt\n",
            "Rail_Challenge_Starter.ipynb\n",
            "\n",
            "Setting up directory structure...\n",
            "\n",
            "Loading and preprocessing data...\n",
            "Data loaded successfully!\n",
            "\n",
            "Setup completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# First, mount Google Drive and set up the environment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import yaml\n",
        "import shutil\n",
        "import multiprocessing\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q ultralytics\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    \"\"\"Global configuration settings\"\"\"\n",
        "    SEED = 42\n",
        "    IMAGE_SIZE = 1024\n",
        "    BATCH_SIZE = 8\n",
        "    EPOCHS = 10\n",
        "    TRAIN_TEST_SPLIT = 0.25\n",
        "    DEVICE = \"cpu\"  # Use \"cpu\" if GPU is not available\n",
        "    MODEL_TYPE = 'yolov8n.pt'  # Base model architecture\n",
        "\n",
        "# Define the base path to your project directory in Google Drive\n",
        "BASE_PATH = '/content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i'\n",
        "\n",
        "# Directory Structure Setup\n",
        "class DirectoryManager:\n",
        "    \"\"\"Manages directory structure for the project\"\"\"\n",
        "    def __init__(self, base_path: str):\n",
        "        self.base_path = Path(base_path)\n",
        "        self.dataset_dir = Path('/content/datasets/dataset')  # Local working directory\n",
        "        self.setup_directories()\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Creates necessary directory structure\"\"\"\n",
        "        # Define directory structure\n",
        "        self.dirs = {\n",
        "            'images': {\n",
        "                'train': self.dataset_dir / 'images/train',\n",
        "                'val': self.dataset_dir / 'images/val',\n",
        "                'test': self.dataset_dir / 'images/test'\n",
        "            },\n",
        "            'labels': {\n",
        "                'train': self.dataset_dir / 'labels/train',\n",
        "                'val': self.dataset_dir / 'labels/val',\n",
        "                'test': self.dataset_dir / 'labels/test'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Create directories\n",
        "        for category in self.dirs.values():\n",
        "            for dir_path in category.values():\n",
        "                if dir_path.exists():\n",
        "                    shutil.rmtree(str(dir_path))\n",
        "                dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Data Preprocessing\n",
        "class DataPreprocessor:\n",
        "    \"\"\"Handles data preprocessing and preparation\"\"\"\n",
        "    def __init__(self, base_path: Path):\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and prepare training and testing data\"\"\"\n",
        "        try:\n",
        "            # Load CSV files with explicit path\n",
        "            self.train_df = pd.read_csv(self.base_path / 'Train.csv')\n",
        "            self.test_df = pd.read_csv(self.base_path / 'Test.csv')\n",
        "\n",
        "            # Unzip images if needed\n",
        "            images_zip_path = self.base_path / 'images.zip'\n",
        "            if images_zip_path.exists():\n",
        "                !unzip -q \"{str(images_zip_path)}\" -d \"/content/images\"\n",
        "\n",
        "            # Add image paths\n",
        "            self.train_df['image_path'] = [\n",
        "                Path('/content/images/' + x) for x in self.train_df.Image_ID\n",
        "            ]\n",
        "            self.test_df['image_path'] = [\n",
        "                Path('/content/images/' + x) for x in self.test_df.Image_ID\n",
        "            ]\n",
        "\n",
        "            # Create class mappings\n",
        "            self.create_class_mappings()\n",
        "            print(\"Data loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def create_class_mappings(self):\n",
        "        \"\"\"Create mappings between class names and indices\"\"\"\n",
        "        unique_classes = sorted(self.train_df['class'].unique().tolist())\n",
        "        self.class_mapper = {\n",
        "            x: y for x, y in zip(unique_classes, range(len(unique_classes)))\n",
        "        }\n",
        "        self.train_df['class_id'] = self.train_df['class'].map(self.class_mapper)\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    try:\n",
        "        # Initialize configuration\n",
        "        config = Config()\n",
        "\n",
        "        # Print current working directory and available files\n",
        "        print(\"Current working directory:\", os.getcwd())\n",
        "        print(\"\\nFiles in base directory:\")\n",
        "        !ls \"{BASE_PATH}\"\n",
        "\n",
        "        # Initialize directory manager\n",
        "        print(\"\\nSetting up directory structure...\")\n",
        "        dir_manager = DirectoryManager(BASE_PATH)\n",
        "\n",
        "        # Initialize data preprocessor\n",
        "        print(\"\\nLoading and preprocessing data...\")\n",
        "        preprocessor = DataPreprocessor(Path(BASE_PATH))\n",
        "        preprocessor.load_data()\n",
        "\n",
        "        # Continue with the rest of the pipeline...\n",
        "        print(\"\\nSetup completed successfully!\")\n",
        "\n",
        "        return preprocessor, dir_manager\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {e}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocessor, dir_manager = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    \"\"\"\n",
        "    Data Preprocessor for Crop Disease Detection\n",
        "    Handles data loading, preprocessing, and augmentation\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the DataPreprocessor with necessary attributes\n",
        "        \"\"\"\n",
        "        # Paths\n",
        "        self.base_path = Path('/content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i')\n",
        "        self.dataset_path = Path('/content/dataset')\n",
        "\n",
        "        # DataFrames\n",
        "        self.train_df = None\n",
        "        self.test_df = None\n",
        "        self.val_df = None\n",
        "\n",
        "        # Class mapping\n",
        "        self.class_mapper = {}\n",
        "        self.num_classes = 0\n",
        "\n",
        "        # Statistics\n",
        "        self.class_distribution = None\n",
        "        self.image_dimensions = []\n",
        "\n",
        "        # Create necessary directories\n",
        "        self._create_directories()\n",
        "\n",
        "    def _create_directories(self):\n",
        "        \"\"\"Create necessary directories for data processing\"\"\"\n",
        "        directories = [\n",
        "            self.dataset_path / 'images' / x for x in ['train', 'val', 'test']\n",
        "        ] + [\n",
        "            self.dataset_path / 'labels' / x for x in ['train', 'val', 'test']\n",
        "        ]\n",
        "\n",
        "        for dir_path in directories:\n",
        "            dir_path.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"Created directory: {dir_path}\")\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Load and prepare the dataset\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"Loading dataset...\")\n",
        "\n",
        "            # Load CSV files\n",
        "            self.train_df = pd.read_csv(self.base_path / 'Train.csv')\n",
        "            self.test_df = pd.read_csv(self.base_path / 'Test.csv')\n",
        "\n",
        "            # Unzip images if needed\n",
        "            images_zip_path = self.base_path / 'images.zip'\n",
        "            if images_zip_path.exists():\n",
        "                print(\"Extracting images...\")\n",
        "                !unzip -q \"{str(images_zip_path)}\" -d \"/content/images\"\n",
        "\n",
        "            # Add image paths\n",
        "            self.train_df['image_path'] = [\n",
        "                Path('/content/images/' + x) for x in self.train_df.Image_ID\n",
        "            ]\n",
        "            self.test_df['image_path'] = [\n",
        "                Path('/content/images/' + x) for x in self.test_df.Image_ID\n",
        "            ]\n",
        "\n",
        "            # Create class mappings\n",
        "            self.create_class_mappings()\n",
        "\n",
        "            # Analyze dataset\n",
        "            self._analyze_dataset()\n",
        "\n",
        "            print(\"Data loaded successfully!\")\n",
        "            self.print_dataset_info()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def create_class_mappings(self):\n",
        "        \"\"\"\n",
        "        Create mappings between class names and indices\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Get unique classes and sort them\n",
        "            unique_classes = sorted(self.train_df['class'].unique().tolist())\n",
        "\n",
        "            # Create mapping dictionary\n",
        "            self.class_mapper = {\n",
        "                class_name: idx for idx, class_name in enumerate(unique_classes)\n",
        "            }\n",
        "            self.num_classes = len(self.class_mapper)\n",
        "\n",
        "            # Add class IDs to training data\n",
        "            self.train_df['class_id'] = self.train_df['class'].map(self.class_mapper)\n",
        "\n",
        "            print(f\"Created mappings for {self.num_classes} classes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating class mappings: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _analyze_dataset(self):\n",
        "        \"\"\"\n",
        "        Analyze the dataset and compute statistics\n",
        "        \"\"\"\n",
        "        print(\"\\nAnalyzing dataset...\")\n",
        "\n",
        "        # Class distribution\n",
        "        self.class_distribution = self.train_df['class'].value_counts()\n",
        "\n",
        "        # Image dimensions\n",
        "        print(\"Calculating image dimensions...\")\n",
        "        for img_path in tqdm(self.train_df['image_path'].unique()):\n",
        "            try:\n",
        "                img = cv2.imread(str(img_path))\n",
        "                if img is not None:\n",
        "                    self.image_dimensions.append(img.shape[:2])\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not read image {img_path}: {e}\")\n",
        "\n",
        "    def print_dataset_info(self):\n",
        "        \"\"\"\n",
        "        Print dataset statistics and information\n",
        "        \"\"\"\n",
        "        print(\"\\n=== Dataset Information ===\")\n",
        "        print(f\"Total training images: {len(self.train_df['Image_ID'].unique())}\")\n",
        "        print(f\"Total test images: {len(self.test_df)}\")\n",
        "        print(f\"Number of classes: {self.num_classes}\")\n",
        "\n",
        "        print(\"\\nClass Distribution:\")\n",
        "        for class_name, count in self.class_distribution.items():\n",
        "            print(f\"{class_name}: {count} ({count/len(self.train_df)*100:.2f}%)\")\n",
        "\n",
        "        if self.image_dimensions:\n",
        "            heights, widths = zip(*self.image_dimensions)\n",
        "            print(f\"\\nImage Dimensions:\")\n",
        "            print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.0f}\")\n",
        "            print(f\"Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.0f}\")\n",
        "\n",
        "    def prepare_yolo_dataset(self):\n",
        "        \"\"\"\n",
        "        Prepare the dataset in YOLO format\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\nPreparing YOLO dataset...\")\n",
        "\n",
        "            # Split data into train and validation sets\n",
        "            train_imgs, val_imgs = self._split_dataset()\n",
        "\n",
        "            # Process training set\n",
        "            self._process_split(train_imgs, 'train')\n",
        "\n",
        "            # Process validation set\n",
        "            self._process_split(val_imgs, 'val')\n",
        "\n",
        "            # Process test set\n",
        "            self._process_test_set()\n",
        "\n",
        "            # Create YAML file\n",
        "            yaml_path = self._create_yaml_file()\n",
        "\n",
        "            print(\"YOLO dataset preparation completed!\")\n",
        "            return yaml_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing YOLO dataset: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _split_dataset(self):\n",
        "        \"\"\"Split dataset into training and validation sets\"\"\"\n",
        "        unique_images = self.train_df.drop_duplicates(subset=['Image_ID'])\n",
        "        return train_test_split(\n",
        "            unique_images,\n",
        "            test_size=0.25,\n",
        "            random_state=42,\n",
        "            stratify=unique_images['class']\n",
        "        )\n",
        "\n",
        "    def _process_split(self, image_group, split_name):\n",
        "        \"\"\"Process a data split (train/val)\"\"\"\n",
        "        print(f\"\\nProcessing {split_name} split...\")\n",
        "\n",
        "        img_dir = self.dataset_path / 'images' / split_name\n",
        "        label_dir = self.dataset_path / 'labels' / split_name\n",
        "\n",
        "        for _, row in tqdm(image_group.iterrows(), desc=f\"Processing {split_name} images\"):\n",
        "            # Copy image\n",
        "            src_path = row['image_path']\n",
        "            dst_path = img_dir / src_path.name\n",
        "            shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "            # Create YOLO format labels\n",
        "            self._create_yolo_label(row, label_dir)\n",
        "\n",
        "    def _create_yolo_label(self, row, label_dir):\n",
        "        \"\"\"Create YOLO format label file for an image\"\"\"\n",
        "        img_path = row['image_path']\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read image {img_path}\")\n",
        "            return\n",
        "\n",
        "        height, width = img.shape[:2]\n",
        "        annotations = self.train_df[self.train_df.Image_ID == row.Image_ID]\n",
        "\n",
        "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, ann in annotations.iterrows():\n",
        "                # Convert to YOLO format\n",
        "                x_center = ((ann['xmin'] + ann['xmax']) / 2) / width\n",
        "                y_center = ((ann['ymin'] + ann['ymax']) / 2) / height\n",
        "                box_width = (ann['xmax'] - ann['xmin']) / width\n",
        "                box_height = (ann['ymax'] - ann['ymin']) / height\n",
        "\n",
        "                f.write(f\"{ann['class_id']} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "    def _process_test_set(self):\n",
        "        \"\"\"Process test set images\"\"\"\n",
        "        print(\"\\nProcessing test set...\")\n",
        "        test_dir = self.dataset_path / 'images' / 'test'\n",
        "\n",
        "        for _, row in tqdm(self.test_df.iterrows(), desc=\"Copying test images\"):\n",
        "            src_path = row['image_path']\n",
        "            dst_path = test_dir / src_path.name\n",
        "            shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "    def _create_yaml_file(self):\n",
        "        \"\"\"Create YAML configuration file for YOLO\"\"\"\n",
        "        yaml_path = 'data.yaml'\n",
        "        yaml_content = {\n",
        "            'path': str(self.dataset_path),\n",
        "            'train': str(self.dataset_path / 'images/train'),\n",
        "            'val': str(self.dataset_path / 'images/val'),\n",
        "            'test': str(self.dataset_path / 'images/test'),\n",
        "            'nc': self.num_classes,\n",
        "            'names': list(self.class_mapper.keys())\n",
        "        }\n",
        "\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(yaml_content, f, default_flow_style=False)\n",
        "\n",
        "        print(f\"\\nCreated YAML configuration file: {yaml_path}\")\n",
        "        print(\"\\nYAML contents:\")\n",
        "        !cat {yaml_path}\n",
        "\n",
        "        return yaml_path"
      ],
      "metadata": {
        "id": "r8vo4eCDJKYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def verify_and_fix_paths():\n",
        "    \"\"\"Verify and fix all necessary paths.\"\"\"\n",
        "    print(\"Verifying paths and files...\")\n",
        "\n",
        "    # Get current working directory\n",
        "    cwd = os.getcwd()\n",
        "    print(f\"Current working directory: {cwd}\")\n",
        "\n",
        "    # List all files in the current directory\n",
        "    print(\"\\nFiles in current directory:\")\n",
        "    !ls -la\n",
        "\n",
        "    # Create dataset directories\n",
        "    dataset_path = Path('/content/dataset')\n",
        "    images_path = dataset_path / 'images'\n",
        "    labels_path = dataset_path / 'labels'\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    for p in [dataset_path, images_path, labels_path]:\n",
        "        p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return dataset_path, images_path, labels_path\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self, base_path: Path):\n",
        "        self.base_path = base_path\n",
        "        self.dataset_path = Path('/content/dataset')\n",
        "        self.class_mapper = {}  # Initialize class mapper\n",
        "\n",
        "    def create_class_mappings(self):\n",
        "        \"\"\"Create a mapping from class names to numerical IDs.\"\"\"\n",
        "        # Get the unique class names from the dataset\n",
        "        class_names = self.train_df['class'].unique()\n",
        "\n",
        "        # Create a mapping from class names to numeric IDs\n",
        "        self.class_mapper = {name: idx for idx, name in enumerate(class_names)}\n",
        "        print(f\"Class mappings created: {self.class_mapper}\")\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and prepare training and testing data.\"\"\"\n",
        "        try:\n",
        "            # Load CSV files with explicit path\n",
        "            print(f\"Loading data from {self.base_path}\")\n",
        "            self.train_df = pd.read_csv(self.base_path / 'Train.csv')\n",
        "            self.test_df = pd.read_csv(self.base_path / 'Test.csv')\n",
        "\n",
        "            # Unzip images if needed\n",
        "            images_zip_path = self.base_path / 'images.zip'\n",
        "            if images_zip_path.exists():\n",
        "                print(f\"Unzipping images from {images_zip_path}\")\n",
        "                !unzip -q \"{str(images_zip_path)}\" -d \"/content/images\"\n",
        "\n",
        "            # Add image paths\n",
        "            self.train_df['image_path'] = [\n",
        "                Path('/content/images/' + x) for x in self.train_df.Image_ID\n",
        "            ]\n",
        "            self.test_df['image_path'] = [\n",
        "                Path('/content/images/' + x) for x in self.test_df.Image_ID\n",
        "            ]\n",
        "\n",
        "            # Create class mappings\n",
        "            self.create_class_mappings()\n",
        "            print(\"Data loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_yolo_dataset(self):\n",
        "        \"\"\"Prepare dataset in YOLO format.\"\"\"\n",
        "        try:\n",
        "            print(\"Preparing YOLO dataset...\")\n",
        "\n",
        "            # Create necessary directories\n",
        "            train_dir = self.dataset_path / 'images/train'\n",
        "            val_dir = self.dataset_path / 'images/val'\n",
        "            test_dir = self.dataset_path / 'images/test'\n",
        "\n",
        "            train_labels_dir = self.dataset_path / 'labels/train'\n",
        "            val_labels_dir = self.dataset_path / 'labels/val'\n",
        "            test_labels_dir = self.dataset_path / 'labels/test'\n",
        "\n",
        "            # Create all directories\n",
        "            for d in [train_dir, val_dir, test_dir, train_labels_dir, val_labels_dir, test_labels_dir]:\n",
        "                d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Split data into train and validation sets\n",
        "            unique_images = self.train_df.drop_duplicates(subset=['Image_ID'])\n",
        "            train_imgs, val_imgs = train_test_split(\n",
        "                unique_images,\n",
        "                test_size=0.25,\n",
        "                random_state=42,\n",
        "                stratify=unique_images['class']\n",
        "            )\n",
        "\n",
        "            # Process train and validation sets\n",
        "            def process_dataset(image_group, img_dir, label_dir, set_name):\n",
        "                print(f\"\\nProcessing {set_name} set...\")\n",
        "                for _, row in tqdm(image_group.iterrows()):\n",
        "                    # Copy image\n",
        "                    src_path = row['image_path']\n",
        "                    dst_path = img_dir / src_path.name\n",
        "                    shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "                    # Create labels\n",
        "                    image_annotations = self.train_df[self.train_df.Image_ID == row.Image_ID]\n",
        "                    label_path = label_dir / f\"{src_path.stem}.txt\"\n",
        "\n",
        "                    # Get image dimensions\n",
        "                    img = cv2.imread(str(src_path))\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not read image {src_path}\")\n",
        "                        continue\n",
        "                    height, width = img.shape[:2]\n",
        "\n",
        "                    with open(label_path, 'w') as f:\n",
        "                        for _, ann in image_annotations.iterrows():\n",
        "                            # Convert to YOLO format\n",
        "                            x_center = ((ann['xmin'] + ann['xmax']) / 2) / width\n",
        "                            y_center = ((ann['ymin'] + ann['ymax']) / 2) / height\n",
        "                            box_width = (ann['xmax'] - ann['xmin']) / width\n",
        "                            box_height = (ann['ymax'] - ann['ymin']) / height\n",
        "                            class_id = self.class_mapper[ann['class']]\n",
        "\n",
        "                            # Write YOLO format line\n",
        "                            f.write(f\"{class_id} {x_center} {y_center} {box_width} {box_height}\\n\")\n",
        "\n",
        "            # Process datasets\n",
        "            process_dataset(train_imgs, train_dir, train_labels_dir, \"training\")\n",
        "            process_dataset(val_imgs, val_dir, val_labels_dir, \"validation\")\n",
        "\n",
        "            # Copy test images\n",
        "            print(\"\\nProcessing test set...\")\n",
        "            for _, row in tqdm(self.test_df.iterrows()):\n",
        "                src_path = row['image_path']\n",
        "                dst_path = test_dir / src_path.name\n",
        "                shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "            # Create data.yaml file\n",
        "            print(\"\\nCreating data.yaml file...\")\n",
        "            data_yaml = {\n",
        "                'path': str(self.dataset_path),  # Base path\n",
        "                'train': str(train_dir),  # Train images path\n",
        "                'val': str(val_dir),      # Validation images path\n",
        "                'test': str(test_dir),    # Test images path\n",
        "                'nc': len(self.class_mapper),  # Number of classes\n",
        "                'names': list(self.class_mapper.keys())  # Class names\n",
        "            }\n",
        "\n",
        "            yaml_path = 'data.yaml'\n",
        "            with open(yaml_path, 'w') as f:\n",
        "                yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "            print(f\"Dataset prepared successfully! YAML file created at: {yaml_path}\")\n",
        "            print(\"\\nYAML contents:\")\n",
        "            !cat data.yaml\n",
        "\n",
        "            return yaml_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing YOLO dataset: {e}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize configuration\n",
        "        config = Config()  # Ensure Config is defined elsewhere\n",
        "\n",
        "        # Verify and fix paths\n",
        "        dataset_path, images_path, labels_path = verify_and_fix_paths()\n",
        "\n",
        "        # Initialize data preprocessor\n",
        "        print(\"\\nInitializing data preprocessor...\")\n",
        "        preprocessor = DataPreprocessor(Path(BASE_PATH))  # Ensure BASE_PATH is set elsewhere\n",
        "\n",
        "        # Load data\n",
        "        print(\"\\nLoading data...\")\n",
        "        preprocessor.load_data()\n",
        "\n",
        "        # Prepare YOLO dataset\n",
        "        print(\"\\nPreparing YOLO dataset...\")\n",
        "        yaml_path = preprocessor.prepare_yolo_dataset()\n",
        "\n",
        "        # Initialize model training\n",
        "        print(\"\\nInitializing model training...\")\n",
        "        trainer = ModelTrainer(config)  # Ensure ModelTrainer is defined elsewhere\n",
        "        training_results = trainer.train(yaml_path)\n",
        "\n",
        "        return preprocessor, trainer, training_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError in main execution: {e}\")\n",
        "        raise\n",
        "\n",
        "# Execute the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    preprocessor, trainer, results = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "OfNq5FjzKwcr",
        "outputId": "fbb87581-9717-43d3-9051-24feff174c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error in main execution: name 'Config' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Config' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-afad4adac9d2>\u001b[0m in \u001b[0;36m<cell line: 205>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;31m# Execute the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-afad4adac9d2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Initialize configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure Config is defined elsewhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Verify and fix paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure Ultralytics YOLO is installed\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "except ImportError:\n",
        "    print(\"Ultralytics YOLO not found. Installing...\")\n",
        "    !pip install ultralytics\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "# Define BASE_PATH\n",
        "BASE_PATH = '/content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i'  # Update this path as needed\n",
        "\n",
        "def verify_and_fix_paths():\n",
        "    \"\"\"Verify and fix all necessary paths.\"\"\"\n",
        "    print(\"Verifying paths and files...\")\n",
        "\n",
        "    # Get current working directory\n",
        "    cwd = os.getcwd()\n",
        "    print(f\"Current working directory: {cwd}\")\n",
        "\n",
        "    # List all files in the current directory\n",
        "    print(\"\\nFiles in current directory:\")\n",
        "    !ls -la\n",
        "\n",
        "    # Create dataset directories\n",
        "    dataset_path = Path('/content/dataset')\n",
        "    images_path = dataset_path / 'images'\n",
        "    labels_path = dataset_path / 'labels'\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    for p in [dataset_path, images_path, labels_path]:\n",
        "        p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return dataset_path, images_path, labels_path\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings for data preprocessing and model training.\"\"\"\n",
        "    def __init__(self):\n",
        "        # Data Preprocessing Configurations\n",
        "        self.base_path = Path(BASE_PATH)\n",
        "        self.dataset_path = Path('/content/dataset')\n",
        "        self.images_dir = self.dataset_path / 'images'\n",
        "        self.labels_dir = self.dataset_path / 'labels'\n",
        "\n",
        "        # YOLO Model Training Configurations\n",
        "        self.model_weights = 'yolov8n.pt'  # Pretrained YOLOv8n model\n",
        "        self.img_size = 640\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 50\n",
        "        self.learning_rate = 0.01\n",
        "        self.data_yaml = 'data.yaml'  # Path to data.yaml file\n",
        "        self.project = 'runs/train'  # Directory to save training runs\n",
        "        self.name = 'yolov8n_custom'  # Name of the training run\n",
        "        self.device = '0'  # GPU device, set to 'cpu' if GPU not available\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.base_path = self.config.base_path\n",
        "        self.dataset_path = self.config.dataset_path\n",
        "        self.images_path = self.config.images_dir\n",
        "        self.labels_path = self.config.labels_dir\n",
        "        self.class_mapper = {}  # Initialize class mapper\n",
        "\n",
        "    def create_class_mappings(self):\n",
        "        \"\"\"Create a mapping from class names to numerical IDs.\"\"\"\n",
        "        # Get the unique class names from the dataset\n",
        "        class_names = self.train_df['class'].unique()\n",
        "\n",
        "        # Create a mapping from class names to numeric IDs\n",
        "        self.class_mapper = {name: idx for idx, name in enumerate(sorted(class_names))}\n",
        "        print(f\"Class mappings created: {self.class_mapper}\")\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and prepare training and testing data.\"\"\"\n",
        "        try:\n",
        "            # Load CSV files with explicit path\n",
        "            print(f\"Loading data from {self.base_path}\")\n",
        "            self.train_df = pd.read_csv(self.base_path / 'Train.csv')\n",
        "            self.test_df = pd.read_csv(self.base_path / 'Test.csv')\n",
        "\n",
        "            # Unzip images if needed\n",
        "            images_zip_path = self.base_path / 'images.zip'\n",
        "            if images_zip_path.exists():\n",
        "                print(f\"Unzipping images from {images_zip_path}\")\n",
        "                !unzip -o -q \"{str(images_zip_path)}\" -d \"/content/images\"\n",
        "            else:\n",
        "                print(f\"No images.zip found at {images_zip_path}. Assuming images are already extracted.\")\n",
        "\n",
        "            # Add image paths\n",
        "            self.train_df['image_path'] = self.train_df['Image_ID'].apply(lambda x: Path('/content/images') / x)\n",
        "            self.test_df['image_path'] = self.test_df['Image_ID'].apply(lambda x: Path('/content/images') / x)\n",
        "\n",
        "            # Create class mappings\n",
        "            self.create_class_mappings()\n",
        "            print(\"Data loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_yolo_dataset(self):\n",
        "        \"\"\"Prepare dataset in YOLO format.\"\"\"\n",
        "        try:\n",
        "            print(\"Preparing YOLO dataset...\")\n",
        "\n",
        "            # Create necessary directories\n",
        "            train_dir = self.dataset_path / 'images/train'\n",
        "            val_dir = self.dataset_path / 'images/val'\n",
        "            test_dir = self.dataset_path / 'images/test'\n",
        "\n",
        "            train_labels_dir = self.dataset_path / 'labels/train'\n",
        "            val_labels_dir = self.dataset_path / 'labels/val'\n",
        "            test_labels_dir = self.dataset_path / 'labels/test'\n",
        "\n",
        "            # Create all directories\n",
        "            for d in [train_dir, val_dir, test_dir, train_labels_dir, val_labels_dir, test_labels_dir]:\n",
        "                d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Split data into train and validation sets\n",
        "            unique_images = self.train_df.drop_duplicates(subset=['Image_ID'])\n",
        "            train_imgs, val_imgs = train_test_split(\n",
        "                unique_images,\n",
        "                test_size=0.25,\n",
        "                random_state=42,\n",
        "                stratify=unique_images['class']\n",
        "            )\n",
        "\n",
        "            # Process train and validation sets\n",
        "            def process_dataset(image_group, img_dir, label_dir, set_name):\n",
        "                print(f\"\\nProcessing {set_name} set...\")\n",
        "                for _, row in tqdm(image_group.iterrows(), total=image_group.shape[0]):\n",
        "                    # Copy image\n",
        "                    src_path = row['image_path']\n",
        "                    dst_path = img_dir / src_path.name\n",
        "                    if not dst_path.exists():\n",
        "                        shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "                    # Create labels\n",
        "                    image_annotations = self.train_df[self.train_df.Image_ID == row.Image_ID]\n",
        "                    label_path = label_dir / f\"{src_path.stem}.txt\"\n",
        "\n",
        "                    # Get image dimensions\n",
        "                    img = cv2.imread(str(src_path))\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not read image {src_path}\")\n",
        "                        continue\n",
        "                    height, width = img.shape[:2]\n",
        "\n",
        "                    with open(label_path, 'w') as f:\n",
        "                        for _, ann in image_annotations.iterrows():\n",
        "                            # Convert to YOLO format\n",
        "                            x_center = ((ann['xmin'] + ann['xmax']) / 2) / width\n",
        "                            y_center = ((ann['ymin'] + ann['ymax']) / 2) / height\n",
        "                            box_width = (ann['xmax'] - ann['xmin']) / width\n",
        "                            box_height = (ann['ymax'] - ann['ymin']) / height\n",
        "                            class_id = self.class_mapper.get(ann['class'])\n",
        "\n",
        "                            if class_id is None:\n",
        "                                print(f\"Warning: Class '{ann['class']}' not found in class_mapper.\")\n",
        "                                continue\n",
        "\n",
        "                            # Write YOLO format line\n",
        "                            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "            # Process datasets\n",
        "            process_dataset(train_imgs, train_dir, train_labels_dir, \"training\")\n",
        "            process_dataset(val_imgs, val_dir, val_labels_dir, \"validation\")\n",
        "\n",
        "            # Copy test images\n",
        "            print(\"\\nProcessing test set...\")\n",
        "            for _, row in tqdm(self.test_df.iterrows(), total=self.test_df.shape[0]):\n",
        "                src_path = row['image_path']\n",
        "                dst_path = test_dir / src_path.name\n",
        "                if not dst_path.exists():\n",
        "                    shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "            # Create data.yaml file\n",
        "            print(\"\\nCreating data.yaml file...\")\n",
        "            data_yaml = {\n",
        "                'path': str(self.dataset_path.resolve()),  # Base path\n",
        "                'train': 'images/train',  # Relative path from 'path'\n",
        "                'val': 'images/val',      # Relative path from 'path'\n",
        "                'test': 'images/test',    # Relative path from 'path'\n",
        "                'nc': len(self.class_mapper),  # Number of classes\n",
        "                'names': list(self.class_mapper.keys())  # Class names\n",
        "            }\n",
        "\n",
        "            yaml_path = self.dataset_path / self.config.data_yaml\n",
        "            with open(yaml_path, 'w') as f:\n",
        "                yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "            print(f\"Dataset prepared successfully! YAML file created at: {yaml_path}\")\n",
        "            print(\"\\nYAML contents:\")\n",
        "            print(yaml.dump(data_yaml, default_flow_style=False))\n",
        "\n",
        "            return yaml_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing YOLO dataset: {e}\")\n",
        "            raise\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.model = None  # Placeholder for the YOLO model\n",
        "\n",
        "    def train(self, yaml_path: Path):\n",
        "        \"\"\"Train the YOLOv8 model using the prepared dataset.\"\"\"\n",
        "        try:\n",
        "            print(\"Initializing YOLOv8 model for training...\")\n",
        "            self.model = YOLO(self.config.model_weights)\n",
        "\n",
        "            print(\"Starting training...\")\n",
        "            results = self.model.train(\n",
        "                data=str(yaml_path),\n",
        "                imgsz=self.config.img_size,\n",
        "                batch=self.config.batch_size,\n",
        "                epochs=self.config.epochs,\n",
        "                lr0=self.config.learning_rate,\n",
        "                project=self.config.project,\n",
        "                name=self.config.name,\n",
        "                device=self.config.device,\n",
        "                verbose=True\n",
        "            )\n",
        "            print(\"Training completed successfully!\")\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model training: {e}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize configuration\n",
        "        config = Config()\n",
        "\n",
        "        # Verify and fix paths\n",
        "        dataset_path, images_path, labels_path = verify_and_fix_paths()\n",
        "\n",
        "        # Initialize data preprocessor\n",
        "        print(\"\\nInitializing data preprocessor...\")\n",
        "        preprocessor = DataPreprocessor(config)\n",
        "\n",
        "        # Load data\n",
        "        print(\"\\nLoading data...\")\n",
        "        preprocessor.load_data()\n",
        "\n",
        "        # Prepare YOLO dataset\n",
        "        print(\"\\nPreparing YOLO dataset...\")\n",
        "        yaml_path = preprocessor.prepare_yolo_dataset()\n",
        "\n",
        "        # Initialize model training\n",
        "        print(\"\\nInitializing model training...\")\n",
        "        trainer = ModelTrainer(config)\n",
        "        training_results = trainer.train(yaml_path)\n",
        "\n",
        "        return preprocessor, trainer, training_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError in main execution: {e}\")\n",
        "        raise\n",
        "\n",
        "# Execute the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    preprocessor, trainer, results = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BUvFIzNIcVJP",
        "outputId": "7e22443c-249c-417e-df3a-94f298d8536c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying paths and files...\n",
            "Current working directory: /content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i\n",
            "\n",
            "Files in current directory:\n",
            "total 10885781\n",
            "drwx------ 2 root root        4096 Oct 15 20:33 dataset\n",
            "-rw------- 1 root root         602 Oct 16 21:21 data.yaml\n",
            "drwx------ 2 root root        4096 Oct 16 20:02 ghana-crop-disease-detection-challenge20241003-7123-59ht2i\n",
            "-rw------- 1 root root 11127738191 Oct 12 15:33 images.zip\n",
            "-rw------- 1 root root        1091 Oct 15 09:01 manifest-8517f262e2ca61a7f7ac8fc1d32eb0be20241003-7123-1lvxb66.json\n",
            "-rw------- 1 root root     5763966 Oct 16 19:57 Rail_Challenge_Starter.ipynb\n",
            "drwx------ 3 root root        4096 Oct 16 20:24 runs\n",
            "-rw------- 1 root root     2512842 Oct 15 09:01 SampleSubmission.csv\n",
            "-rw------- 1 root root       42066 Oct 15 09:01 Test.csv\n",
            "-rw------- 1 root root     4416736 Oct 15 09:01 Train.csv\n",
            "-rw------- 1 root root     6549796 Oct 16 20:24 yolov8n.pt\n",
            "\n",
            "Initializing data preprocessor...\n",
            "\n",
            "Loading data...\n",
            "Loading data from /content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i\n",
            "Unzipping images from /content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i/images.zip\n",
            "Class mappings created: {'Corn_Cercospora_Leaf_Spot': 0, 'Corn_Common_Rust': 1, 'Corn_Healthy': 2, 'Corn_Northern_Leaf_Blight': 3, 'Corn_Streak': 4, 'Pepper_Bacterial_Spot': 5, 'Pepper_Cercospora': 6, 'Pepper_Early_Blight': 7, 'Pepper_Fusarium': 8, 'Pepper_Healthy': 9, 'Pepper_Late_Blight': 10, 'Pepper_Leaf_Blight': 11, 'Pepper_Leaf_Curl': 12, 'Pepper_Leaf_Mosaic': 13, 'Pepper_Septoria': 14, 'Tomato_Bacterial_Spot': 15, 'Tomato_Early_Blight': 16, 'Tomato_Fusarium': 17, 'Tomato_Healthy': 18, 'Tomato_Late_Blight': 19, 'Tomato_Leaf_Curl': 20, 'Tomato_Mosaic': 21, 'Tomato_Septoria': 22}\n",
            "Data loaded successfully!\n",
            "\n",
            "Preparing YOLO dataset...\n",
            "Preparing YOLO dataset...\n",
            "\n",
            "Processing training set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3676/3676 [07:36<00:00,  8.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1226/1226 [02:25<00:00,  8.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2101/2101 [00:38<00:00, 54.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating data.yaml file...\n",
            "Dataset prepared successfully! YAML file created at: /content/dataset/data.yaml\n",
            "\n",
            "YAML contents:\n",
            "names:\n",
            "- Corn_Cercospora_Leaf_Spot\n",
            "- Corn_Common_Rust\n",
            "- Corn_Healthy\n",
            "- Corn_Northern_Leaf_Blight\n",
            "- Corn_Streak\n",
            "- Pepper_Bacterial_Spot\n",
            "- Pepper_Cercospora\n",
            "- Pepper_Early_Blight\n",
            "- Pepper_Fusarium\n",
            "- Pepper_Healthy\n",
            "- Pepper_Late_Blight\n",
            "- Pepper_Leaf_Blight\n",
            "- Pepper_Leaf_Curl\n",
            "- Pepper_Leaf_Mosaic\n",
            "- Pepper_Septoria\n",
            "- Tomato_Bacterial_Spot\n",
            "- Tomato_Early_Blight\n",
            "- Tomato_Fusarium\n",
            "- Tomato_Healthy\n",
            "- Tomato_Late_Blight\n",
            "- Tomato_Leaf_Curl\n",
            "- Tomato_Mosaic\n",
            "- Tomato_Septoria\n",
            "nc: 23\n",
            "path: /content/dataset\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n",
            "\n",
            "Initializing model training...\n",
            "Initializing YOLOv8 model for training...\n",
            "Starting training...\n",
            "Ultralytics 8.3.15 🚀 Python-3.10.12 torch-2.4.1+cu121 \n",
            "Error during model training: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n",
            "\n",
            "torch.cuda.is_available(): False\n",
            "torch.cuda.device_count(): 0\n",
            "os.environ['CUDA_VISIBLE_DEVICES']: None\n",
            "See https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
            "\n",
            "\n",
            "Error in main execution: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n",
            "\n",
            "torch.cuda.is_available(): False\n",
            "torch.cuda.device_count(): 0\n",
            "os.environ['CUDA_VISIBLE_DEVICES']: None\n",
            "See https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: None\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6578990cf317>\u001b[0m in \u001b[0;36m<cell line: 273>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;31m# Execute the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-6578990cf317>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nInitializing model training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mtraining_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6578990cf317>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, yaml_path)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             results = self.model.train(\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             )\n\u001b[0;32m--> 192\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0;34mf\"Invalid CUDA 'device={device}' requested.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;34mf\" Use 'device=cpu' or pass valid CUDA device(s) if available,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: None\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure Ultralytics YOLO is installed\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "except ImportError:\n",
        "    print(\"Ultralytics YOLO not found. Installing...\")\n",
        "    !pip install ultralytics\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "# Define BASE_PATH\n",
        "BASE_PATH = '/content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i'  # Update this path as needed\n",
        "\n",
        "def verify_and_fix_paths():\n",
        "    \"\"\"Verify and fix all necessary paths.\"\"\"\n",
        "    print(\"Verifying paths and files...\")\n",
        "\n",
        "    # Get current working directory\n",
        "    cwd = os.getcwd()\n",
        "    print(f\"Current working directory: {cwd}\")\n",
        "\n",
        "    # List all files in the current directory\n",
        "    print(\"\\nFiles in current directory:\")\n",
        "    !ls -la\n",
        "\n",
        "    # Create dataset directories\n",
        "    dataset_path = Path('/content/dataset')\n",
        "    images_path = dataset_path / 'images'\n",
        "    labels_path = dataset_path / 'labels'\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    for p in [dataset_path, images_path, labels_path]:\n",
        "        p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return dataset_path, images_path, labels_path\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings for data preprocessing and model training.\"\"\"\n",
        "    def __init__(self):\n",
        "        # Data Preprocessing Configurations\n",
        "        self.base_path = Path(BASE_PATH)\n",
        "        self.dataset_path = Path('/content/dataset')\n",
        "        self.images_dir = self.dataset_path / 'images'\n",
        "        self.labels_dir = self.dataset_path / 'labels'\n",
        "\n",
        "        # YOLO Model Training Configurations\n",
        "        self.model_weights = 'yolov8n.pt'  # Pretrained YOLOv8n model\n",
        "        self.img_size = 640\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 5\n",
        "        self.learning_rate = 0.01\n",
        "        self.data_yaml = 'data.yaml'  # Path to data.yaml file\n",
        "        self.project = 'runs/train'  # Directory to save training runs\n",
        "        self.name = 'yolov8n_custom'  # Name of the training run\n",
        "        self.device = 'cpu'  # Set to 'cpu' since CUDA device is unavailable\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.base_path = self.config.base_path\n",
        "        self.dataset_path = self.config.dataset_path\n",
        "        self.images_path = self.config.images_dir\n",
        "        self.labels_path = self.config.labels_dir\n",
        "        self.class_mapper = {}  # Initialize class mapper\n",
        "\n",
        "    def create_class_mappings(self):\n",
        "        \"\"\"Create a mapping from class names to numerical IDs.\"\"\"\n",
        "        # Get the unique class names from the dataset\n",
        "        class_names = self.train_df['class'].unique()\n",
        "\n",
        "        # Create a mapping from class names to numeric IDs\n",
        "        self.class_mapper = {name: idx for idx, name in enumerate(sorted(class_names))}\n",
        "        print(f\"Class mappings created: {self.class_mapper}\")\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and prepare training and testing data.\"\"\"\n",
        "        try:\n",
        "            # Load CSV files with explicit path\n",
        "            print(f\"Loading data from {self.base_path}\")\n",
        "            self.train_df = pd.read_csv(self.base_path / 'Train.csv')\n",
        "            self.test_df = pd.read_csv(self.base_path / 'Test.csv')\n",
        "\n",
        "            # Unzip images if needed\n",
        "            images_zip_path = self.base_path / 'images.zip'\n",
        "            if images_zip_path.exists():\n",
        "                print(f\"Unzipping images from {images_zip_path}\")\n",
        "                !unzip -o -q \"{str(images_zip_path)}\" -d \"/content/images\"\n",
        "            else:\n",
        "                print(f\"No images.zip found at {images_zip_path}. Assuming images are already extracted.\")\n",
        "\n",
        "            # Add image paths\n",
        "            self.train_df['image_path'] = self.train_df['Image_ID'].apply(lambda x: Path('/content/images') / x)\n",
        "            self.test_df['image_path'] = self.test_df['Image_ID'].apply(lambda x: Path('/content/images') / x)\n",
        "\n",
        "            # Create class mappings\n",
        "            self.create_class_mappings()\n",
        "            print(\"Data loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_yolo_dataset(self):\n",
        "        \"\"\"Prepare dataset in YOLO format.\"\"\"\n",
        "        try:\n",
        "            print(\"Preparing YOLO dataset...\")\n",
        "\n",
        "            # Create necessary directories\n",
        "            train_dir = self.dataset_path / 'images/train'\n",
        "            val_dir = self.dataset_path / 'images/val'\n",
        "            test_dir = self.dataset_path / 'images/test'\n",
        "\n",
        "            train_labels_dir = self.dataset_path / 'labels/train'\n",
        "            val_labels_dir = self.dataset_path / 'labels/val'\n",
        "            test_labels_dir = self.dataset_path / 'labels/test'\n",
        "\n",
        "            # Create all directories\n",
        "            for d in [train_dir, val_dir, test_dir, train_labels_dir, val_labels_dir, test_labels_dir]:\n",
        "                d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Split data into train and validation sets\n",
        "            unique_images = self.train_df.drop_duplicates(subset=['Image_ID'])\n",
        "            train_imgs, val_imgs = train_test_split(\n",
        "                unique_images,\n",
        "                test_size=0.25,\n",
        "                random_state=42,\n",
        "                stratify=unique_images['class']\n",
        "            )\n",
        "\n",
        "            # Process train and validation sets\n",
        "            def process_dataset(image_group, img_dir, label_dir, set_name):\n",
        "                print(f\"\\nProcessing {set_name} set...\")\n",
        "                for _, row in tqdm(image_group.iterrows(), total=image_group.shape[0]):\n",
        "                    # Copy image\n",
        "                    src_path = row['image_path']\n",
        "                    dst_path = img_dir / src_path.name\n",
        "                    if not dst_path.exists():\n",
        "                        shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "                    # Create labels\n",
        "                    image_annotations = self.train_df[self.train_df.Image_ID == row.Image_ID]\n",
        "                    label_path = label_dir / f\"{src_path.stem}.txt\"\n",
        "\n",
        "                    # Get image dimensions\n",
        "                    img = cv2.imread(str(src_path))\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not read image {src_path}\")\n",
        "                        continue\n",
        "                    height, width = img.shape[:2]\n",
        "\n",
        "                    with open(label_path, 'w') as f:\n",
        "                        for _, ann in image_annotations.iterrows():\n",
        "                            # Convert to YOLO format\n",
        "                            x_center = ((ann['xmin'] + ann['xmax']) / 2) / width\n",
        "                            y_center = ((ann['ymin'] + ann['ymax']) / 2) / height\n",
        "                            box_width = (ann['xmax'] - ann['xmin']) / width\n",
        "                            box_height = (ann['ymax'] - ann['ymin']) / height\n",
        "                            class_id = self.class_mapper.get(ann['class'])\n",
        "\n",
        "                            if class_id is None:\n",
        "                                print(f\"Warning: Class '{ann['class']}' not found in class_mapper.\")\n",
        "                                continue\n",
        "\n",
        "                            # Write YOLO format line\n",
        "                            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "            # Process datasets\n",
        "            process_dataset(train_imgs, train_dir, train_labels_dir, \"training\")\n",
        "            process_dataset(val_imgs, val_dir, val_labels_dir, \"validation\")\n",
        "\n",
        "            # Copy test images\n",
        "            print(\"\\nProcessing test set...\")\n",
        "            for _, row in tqdm(self.test_df.iterrows(), total=self.test_df.shape[0]):\n",
        "                src_path = row['image_path']\n",
        "                dst_path = test_dir / src_path.name\n",
        "                if not dst_path.exists():\n",
        "                    shutil.copy(str(src_path), str(dst_path))\n",
        "\n",
        "            # Create data.yaml file\n",
        "            print(\"\\nCreating data.yaml file...\")\n",
        "            data_yaml = {\n",
        "                'path': str(self.dataset_path.resolve()),  # Base path\n",
        "                'train': 'images/train',  # Relative path from 'path'\n",
        "                'val': 'images/val',      # Relative path from 'path'\n",
        "                'test': 'images/test',    # Relative path from 'path'\n",
        "                'nc': len(self.class_mapper),  # Number of classes\n",
        "                'names': list(self.class_mapper.keys())  # Class names\n",
        "            }\n",
        "\n",
        "            yaml_path = self.dataset_path / self.config.data_yaml\n",
        "            with open(yaml_path, 'w') as f:\n",
        "                yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "            print(f\"Dataset prepared successfully! YAML file created at: {yaml_path}\")\n",
        "            print(\"\\nYAML contents:\")\n",
        "            print(yaml.dump(data_yaml, default_flow_style=False))\n",
        "\n",
        "            return yaml_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing YOLO dataset: {e}\")\n",
        "            raise\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.model = None  # Placeholder for the YOLO model\n",
        "\n",
        "    def train(self, yaml_path: Path):\n",
        "        \"\"\"Train the YOLOv8 model using the prepared dataset.\"\"\"\n",
        "        try:\n",
        "            print(\"Initializing YOLOv8 model for training...\")\n",
        "            self.model = YOLO(self.config.model_weights)\n",
        "\n",
        "            print(\"Starting training...\")\n",
        "            results = self.model.train(\n",
        "                data=str(yaml_path),\n",
        "                imgsz=self.config.img_size,\n",
        "                batch=self.config.batch_size,\n",
        "                epochs=self.config.epochs,\n",
        "                lr0=self.config.learning_rate,\n",
        "                project=self.config.project,\n",
        "                name=self.config.name,\n",
        "                device=self.config.device\n",
        "            )\n",
        "            print(\"Training complete!\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model training: {e}\")\n",
        "            raise\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        # Step 1: Create Config Object\n",
        "        config = Config()\n",
        "\n",
        "        # Step 2: Prepare Dataset\n",
        "        preprocessor = DataPreprocessor(config)\n",
        "        preprocessor.load_data()\n",
        "        yaml_path = preprocessor.prepare_yolo_dataset()\n",
        "\n",
        "        # Step 3: Train Model\n",
        "        trainer = ModelTrainer(config)\n",
        "        trainer.train(yaml_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOTBt8KQjtdB",
        "outputId": "96881430-597f-4066-c8b9-cb40bb7149f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i\n",
            "Unzipping images from /content/drive/MyDrive/ghana-crop-disease-detection-challenge20241003-7123-59ht2i/images.zip\n",
            "Class mappings created: {'Corn_Cercospora_Leaf_Spot': 0, 'Corn_Common_Rust': 1, 'Corn_Healthy': 2, 'Corn_Northern_Leaf_Blight': 3, 'Corn_Streak': 4, 'Pepper_Bacterial_Spot': 5, 'Pepper_Cercospora': 6, 'Pepper_Early_Blight': 7, 'Pepper_Fusarium': 8, 'Pepper_Healthy': 9, 'Pepper_Late_Blight': 10, 'Pepper_Leaf_Blight': 11, 'Pepper_Leaf_Curl': 12, 'Pepper_Leaf_Mosaic': 13, 'Pepper_Septoria': 14, 'Tomato_Bacterial_Spot': 15, 'Tomato_Early_Blight': 16, 'Tomato_Fusarium': 17, 'Tomato_Healthy': 18, 'Tomato_Late_Blight': 19, 'Tomato_Leaf_Curl': 20, 'Tomato_Mosaic': 21, 'Tomato_Septoria': 22}\n",
            "Data loaded successfully!\n",
            "Preparing YOLO dataset...\n",
            "\n",
            "Processing training set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3676/3676 [04:47<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1226/1226 [01:34<00:00, 12.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2101/2101 [00:00<00:00, 6652.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating data.yaml file...\n",
            "Dataset prepared successfully! YAML file created at: /content/dataset/data.yaml\n",
            "\n",
            "YAML contents:\n",
            "names:\n",
            "- Corn_Cercospora_Leaf_Spot\n",
            "- Corn_Common_Rust\n",
            "- Corn_Healthy\n",
            "- Corn_Northern_Leaf_Blight\n",
            "- Corn_Streak\n",
            "- Pepper_Bacterial_Spot\n",
            "- Pepper_Cercospora\n",
            "- Pepper_Early_Blight\n",
            "- Pepper_Fusarium\n",
            "- Pepper_Healthy\n",
            "- Pepper_Late_Blight\n",
            "- Pepper_Leaf_Blight\n",
            "- Pepper_Leaf_Curl\n",
            "- Pepper_Leaf_Mosaic\n",
            "- Pepper_Septoria\n",
            "- Tomato_Bacterial_Spot\n",
            "- Tomato_Early_Blight\n",
            "- Tomato_Fusarium\n",
            "- Tomato_Healthy\n",
            "- Tomato_Late_Blight\n",
            "- Tomato_Leaf_Curl\n",
            "- Tomato_Mosaic\n",
            "- Tomato_Septoria\n",
            "nc: 23\n",
            "path: /content/dataset\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n",
            "Initializing YOLOv8 model for training...\n",
            "Starting training...\n",
            "Ultralytics 8.3.15 🚀 Python-3.10.12 torch-2.4.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/dataset/data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=runs/train, name=yolov8n_custom3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/train/yolov8n_custom3\n",
            "Overriding model.yaml nc=80 with nc=23\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    435157  ultralytics.nn.modules.head.Detect           [23, [64, 128, 256]]          \n",
            "Model summary: 249 layers, 2,694,693 parameters, 2,694,677 gradients, 7.0 GFLOPs\n",
            "\n",
            "Transferred 313/391 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train/yolov8n_custom3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 3676 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3676/3676 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 1226 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1226/1226 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/train/yolov8n_custom3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00037, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov8n_custom3\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5         0G      2.642      5.023      1.882         95        640: 100%|██████████| 230/230 [59:39<00:00, 15.56s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [06:29<00:00, 10.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1226      10252      0.351     0.0589     0.0272     0.0101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5         0G      2.493      3.777      1.588        108        640: 100%|██████████| 230/230 [58:39<00:00, 15.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [06:19<00:00,  9.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1226      10252      0.421       0.12       0.06     0.0231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5         0G      2.413      3.291      1.564        154        640: 100%|██████████| 230/230 [58:13<00:00, 15.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [06:31<00:00, 10.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1226      10252       0.26      0.152     0.0723     0.0288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5         0G      2.339      3.039      1.535        191        640: 100%|██████████| 230/230 [56:07<00:00, 14.64s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [06:11<00:00,  9.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1226      10252      0.306      0.178     0.0977      0.039\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5         0G      2.282      2.857       1.51        132        640: 100%|██████████| 230/230 [55:57<00:00, 14.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [06:24<00:00,  9.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1226      10252      0.284      0.183      0.115     0.0467\n",
            "\n",
            "5 epochs completed in 5.348 hours.\n",
            "Optimizer stripped from runs/train/yolov8n_custom3/weights/last.pt, 5.6MB\n",
            "Optimizer stripped from runs/train/yolov8n_custom3/weights/best.pt, 5.6MB\n",
            "\n",
            "Validating runs/train/yolov8n_custom3/weights/best.pt...\n",
            "Ultralytics 8.3.15 🚀 Python-3.10.12 torch-2.4.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 186 layers, 2,688,853 parameters, 0 gradients, 6.8 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [05:13<00:00,  8.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1226      10252      0.328      0.183      0.116     0.0467\n",
            "Corn_Cercospora_Leaf_Spot        202       1600      0.326      0.409      0.281      0.103\n",
            "      Corn_Common_Rust         79        442      0.265       0.36       0.21     0.0815\n",
            "          Corn_Healthy         63        415      0.205      0.354      0.165     0.0572\n",
            "Corn_Northern_Leaf_Blight         12         25          0          0          0          0\n",
            "           Corn_Streak         87        804      0.215      0.541      0.244     0.0763\n",
            " Pepper_Bacterial_Spot        132        476      0.205      0.144     0.0887     0.0214\n",
            "     Pepper_Cercospora         41        121          1          0      0.025    0.00723\n",
            "   Pepper_Early_Blight          2         15          0          0          0          0\n",
            "       Pepper_Fusarium         52        123      0.222      0.179      0.111     0.0362\n",
            "        Pepper_Healthy         68        184      0.316       0.63      0.416      0.176\n",
            "    Pepper_Late_Blight         15        135          1          0     0.0222    0.00704\n",
            "    Pepper_Leaf_Blight         50        121      0.135     0.0496      0.039     0.0141\n",
            "      Pepper_Leaf_Curl        138        374      0.161      0.142     0.0771     0.0193\n",
            "    Pepper_Leaf_Mosaic        147        523     0.0566    0.00191    0.00993     0.0027\n",
            "       Pepper_Septoria         40        697      0.154    0.00681     0.0353     0.0124\n",
            " Tomato_Bacterial_Spot         14        119          1          0     0.0188    0.00894\n",
            "   Tomato_Early_Blight         56        476       0.17      0.176     0.0853     0.0378\n",
            "       Tomato_Fusarium         22        268      0.198      0.134     0.0842     0.0271\n",
            "        Tomato_Healthy         59        747      0.338      0.778       0.52      0.305\n",
            "    Tomato_Late_Blight        105        874      0.148      0.112     0.0631     0.0207\n",
            "      Tomato_Leaf_Curl         17         93      0.225     0.0323     0.0629     0.0286\n",
            "         Tomato_Mosaic          5         32          1          0    0.00149   0.000885\n",
            "       Tomato_Septoria        119       1588        0.2      0.161     0.0976     0.0316\n",
            "Speed: 1.8ms preprocess, 170.5ms inference, 0.0ms loss, 11.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/train/yolov8n_custom3\u001b[0m\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPezA4Mn8LrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.pt')  # Make sure this path is correct\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN_YMU1s_cYa",
        "outputId": "07189159-a33d-4416-92b8-d82b53cb21a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQhBmhXs_iLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}